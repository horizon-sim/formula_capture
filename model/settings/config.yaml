gpu_devices: 0 # [0,1,2,3,4,5,6,7]
backbone_layers:
- 2
- 3
- 7
betas:
- 0.9
- 0.999
batchsize: 64
bos_token: 1
channels: 1
data: dataset/data/train.pkl
debug: false
decoder_args:
  attn_on_attn: true
  cross_attend: true
  ff_glu: true
  rel_pos_bias: false
  use_scalenorm: false
dim: 256
encoder_depth: 6
eos_token: 2
epochs: 100
gamma: 0.1
heads: 8
id: null
load_chkpt: null
lr: 0.001
lr_step: 30
max_height: 192
max_seq_len: 512
max_width: 672
micro_batchsize: 16
min_height: 32
min_width: 32
model_path: checkpoints
num_layers: 4
num_tokens: 8000
optimizer: AdamW
T_0: 20
T_mult: 1
eta_max: 0.001
T_up: 5
weight_decay: 0.01
max_norm: 0.5
output_path: outputs
pad: false
pad_token: 0
patch_size: 16
sample_freq: 3000
save_freq: 1
scheduler: StepLR
seed: 42
encoder_structure: hybrid
temperature: 0.2
test_samples: 5
testbatchsize: 20
tokenizer: model/dataset/tokenizer.json
valbatches: 100
valdata: dataset/data/val.pkl

# adaptFormer
name: af_h_data
is_af: True

# default
#name: p_h_data
#is_af: False
#is_01_lr: False